{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/DELL/.cache/huggingface/datasets/parquet/plain_text-57edf78d6033ac9a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed35f080951041dba37def7e51f72684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForQuestionAnswering, BertModel, BertConfig, BertTokenizer, pipeline, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"squad\")\n",
    "train = dataset['train']\n",
    "validation = dataset['validation']\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model='AliHashish/distilbert-base-uncased-finetuned-squad-EZcufe')\n",
    "model_checkpoint = \"atharvamundada99/bert-large-question-answering-finetuned-legal\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "pretrained_model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# correct = 0\n",
    "# errors = []\n",
    "# for record in tqdm(validation):\n",
    "#         try:\n",
    "#                 total += 1\n",
    "#                 if (total % 1000 == 0):\n",
    "#                         print(f\"Accuracy: {100*correct/total}\")\n",
    "#                         print(f\"Correct: {correct}, out of {total}\")\n",
    "#                 result = question_answerer(question=record['question'], context=record['context'], truncation=True, padding=True, return_tensors='pt')\n",
    "#                 if result['answer'].lower() in record['answers']['text'][0].lower() or record['answers']['text'][0].lower() in result['answer'].lower():\n",
    "#                         correct += 1\n",
    "#         except Exception as e:\n",
    "#                 errors.append(total)\n",
    "#                 print(f\"Error at {total}: {e}\")\n",
    "#                 continue\n",
    "# print(\"Accuracy: \", 100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dh 3lshan ykamel fl iteration lw w2fna fl nos\n",
    "\n",
    "# print(f\"Accuracy: {100*correct/total}\")\n",
    "# print(f\"Correct: {correct}, out of {total}\")\n",
    "# print(f\"Errors: {errors}\")\n",
    "# prev_total = total\n",
    "# total = 0\n",
    "# for record in tqdm(validation):\n",
    "#         try:\n",
    "#                 total += 1\n",
    "#                 if total < prev_total:\n",
    "#                         continue\n",
    "#                 if (total % 1000 == 0):\n",
    "#                         print(f\"Accuracy: {100*correct/total}\")\n",
    "#                         print(f\"Correct: {correct}, out of {total}\")\n",
    "#                 result = question_answerer(question=record['question'], context=record['context'], truncation=True, padding=True, return_tensors='pt')\n",
    "#                 if result['answer'].lower() in record['answers']['text'][0].lower() or record['answers']['text'][0].lower() in result['answer'].lower():\n",
    "#                         correct += 1\n",
    "#         except Exception as e:\n",
    "#                 errors.append(total)\n",
    "#                 print(f\"Error at {total}: {e}\")\n",
    "#                 continue\n",
    "\n",
    "# print(f\"Accuracy: {100*correct/total}\")\n",
    "# print(f\"Correct: {correct}, out of {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get model architecture\n",
    "# print(\"model.config: \", pretrained_model.config)\n",
    "# print(\"============================================================================================\")\n",
    "\n",
    "# # get model parameters\n",
    "# print(\"model.parameters: \", pretrained_model.parameters)\n",
    "# print(\"============================================================================================\")\n",
    "\n",
    "# # get model layers\n",
    "# print(\"model.layers: \", pretrained_model.bert.encoder.layer)\n",
    "# print(\"============================================================================================\")\n",
    "\n",
    "# # get model weights\n",
    "# print(\"model.weights: \", pretrained_model.state_dict())\n",
    "# print(\"============================================================================================\")\n",
    "\n",
    "# print(\"model.layers: \", len(pretrained_model.bert.encoder.layer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.parameters:  <bound method Module.parameters of BertForQuestionAnswering(\n",
    "#   (bert): BertModel(\n",
    "#     (embeddings): BertEmbeddings(\n",
    "#       (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
    "#       (position_embeddings): Embedding(512, 1024)\n",
    "#       (token_type_embeddings): Embedding(2, 1024)\n",
    "#       (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
    "#       (dropout): Dropout(p=0.1, inplace=False)\n",
    "#     )\n",
    "#     (encoder): BertEncoder(\n",
    "#       (layer): ModuleList(\n",
    "#         (0-23): 24 x BertLayer(\n",
    "#           (attention): BertAttention(\n",
    "#             (self): BertSelfAttention(\n",
    "#               (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             )\n",
    "#             (output): BertSelfOutput(\n",
    "#               (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
    "#               (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             )\n",
    "#           )\n",
    "#           (intermediate): BertIntermediate(\n",
    "#             (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
    "#             (intermediate_act_fn): GELUActivation()\n",
    "#           )\n",
    "#           (output): BertOutput(\n",
    "#             (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
    "#             (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#           )\n",
    "#         )\n",
    "#       )\n",
    "#     )\n",
    "#   )\n",
    "#   (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
    "# )>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertForQuestionAnswering(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CustomBertForQuestionAnswering, self).__init__()\n",
    "        self.bert = BertModel(config)\n",
    "        self.qa_outputs = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        return start_logits, end_logits\n",
    "\n",
    "# Instantiate the model with the provided configuration\n",
    "config = BertConfig.from_dict({\n",
    "    \"_name_or_path\": \"ourModel\",\n",
    "    \"architectures\": [\n",
    "        \"BertForQuestionAnswering\"\n",
    "    ],\n",
    "    \"attention_probs_dropout_prob\": 0.1,\n",
    "    \"gradient_checkpointing\": False,\n",
    "    \"hidden_act\": \"gelu\",\n",
    "    \"hidden_dropout_prob\": 0.1,\n",
    "    \"hidden_size\": 1024,\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"intermediate_size\": 4096,\n",
    "    \"layer_norm_eps\": 1e-12,\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"model_type\": \"bert\",\n",
    "    \"num_attention_heads\": 16,\n",
    "    \"num_hidden_layers\": 24,\n",
    "    \"pad_token_id\": 0,\n",
    "    \"position_embedding_type\": \"absolute\",\n",
    "    \"transformers_version\": \"4.17.0\",\n",
    "    \"type_vocab_size\": 2,\n",
    "    \"use_cache\": True,\n",
    "    \"vocab_size\": 30522\n",
    "})\n",
    "\n",
    "model = CustomBertForQuestionAnswering(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get state dictionary of pre-trained model\n",
    "pretrained_dict = pretrained_model.state_dict()\n",
    "\n",
    "# Get state dictionary of custom model\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "print(len(pretrained_dict))\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "print(len(pretrained_dict))\n",
    "\n",
    "# Overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the new state dict\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA(model, tokenizer, question, context):\n",
    "    # Process the inputs\n",
    "    inputs = tokenizer(question, context, return_tensors='pt')\n",
    "\n",
    "    # Pass the inputs through the model and get the start and end scores\n",
    "    start_scores, end_scores = model(**inputs)\n",
    "\n",
    "    # Get the start and end positions\n",
    "    start_position = torch.argmax(start_scores)\n",
    "    end_position = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the answer\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_position:end_position+1]))\n",
    "\n",
    "    return answer\n",
    "\n",
    "def QAs(model, tokenizer, questions, contexts):\n",
    "    answers = []\n",
    "    for question, context in zip(questions, contexts):\n",
    "        answer = QA(model, tokenizer, question, context)\n",
    "        answers.append(answer)\n",
    "    return answers\n",
    "\n",
    "def Evaluation(model, tokenizer, validation):\n",
    "    correct = 0\n",
    "    EM = 0\n",
    "    total = 0\n",
    "    errors = []\n",
    "    for record in tqdm(validation):\n",
    "        try:\n",
    "            total += 1\n",
    "            if (total % 500 == 0):\n",
    "                print(f\"\\nAccuracy: {100*correct/total}\")\n",
    "                print(f\"Correct: {correct}, out of {total}\")\n",
    "                print(f\"EM: {100*EM/total}\")\n",
    "                print(f\"EM Correct: {EM}, out of {total}\\n\")\n",
    "\n",
    "            predicted_answer = QA(model, tokenizer, record['question'], record['context'])\n",
    "            if predicted_answer.lower() in record['answers']['text'][0].lower() or record['answers']['text'][0].lower() in predicted_answer.lower():\n",
    "                correct += 1\n",
    "            if predicted_answer.lower() == record['answers']['text'][0].lower():\n",
    "                EM += 1\n",
    "        except Exception as e:\n",
    "            errors.append(total)\n",
    "            print(f\"Error at {total}: {e} \")\n",
    "            continue\n",
    "    return correct, EM, total"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 999/10570 [11:07<1:53:44,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 84.3\n",
      "Correct: 843, out of 1000\n",
      "EM: 68.0\n",
      "EM Correct: 680, out of 1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1999/10570 [19:06<55:49,  2.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 83.45\n",
      "Correct: 1669, out of 2000\n",
      "EM: 63.5\n",
      "EM Correct: 1270, out of 2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2308/10570 [20:59<1:15:09,  1.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m correct, EM, total \u001b[38;5;241m=\u001b[39m Evaluation(model, tokenizer, validation)\n",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m, in \u001b[0;36mEvaluation\u001b[1;34m(model, tokenizer, validation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mEM\u001b[38;5;241m/\u001b[39mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEM Correct: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m predicted_answer \u001b[38;5;241m=\u001b[39m QA(model, tokenizer, record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_answer\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mor\u001b[39;00m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m predicted_answer\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m     40\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m, in \u001b[0;36mQA\u001b[1;34m(model, tokenizer, question, context)\u001b[0m\n\u001b[0;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(question, context, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pass the inputs through the model and get the start and end scores\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m start_scores, end_scores \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get the start and end positions\u001b[39;00m\n\u001b[0;32m      9\u001b[0m start_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(start_scores)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mCustomBertForQuestionAnswering.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids)\n\u001b[0;32m      9\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m     10\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    995\u001b[0m )\n\u001b[1;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    997\u001b[0m     embedding_output,\n\u001b[0;32m    998\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m    999\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1000\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1001\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1002\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1003\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1004\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1005\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1006\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1007\u001b[0m )\n\u001b[0;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    578\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    583\u001b[0m     )\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    586\u001b[0m         hidden_states,\n\u001b[0;32m    587\u001b[0m         attention_mask,\n\u001b[0;32m    588\u001b[0m         layer_head_mask,\n\u001b[0;32m    589\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    590\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    591\u001b[0m         past_key_value,\n\u001b[0;32m    592\u001b[0m         output_attentions,\n\u001b[0;32m    593\u001b[0m     )\n\u001b[0;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m ):\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    473\u001b[0m         hidden_states,\n\u001b[0;32m    474\u001b[0m         attention_mask,\n\u001b[0;32m    475\u001b[0m         head_mask,\n\u001b[0;32m    476\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    477\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[0;32m    478\u001b[0m     )\n\u001b[0;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    394\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ):\n\u001b[1;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    403\u001b[0m         hidden_states,\n\u001b[0;32m    404\u001b[0m         attention_mask,\n\u001b[0;32m    405\u001b[0m         head_mask,\n\u001b[0;32m    406\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    407\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    408\u001b[0m         past_key_value,\n\u001b[0;32m    409\u001b[0m         output_attentions,\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:291\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 291\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[0;32m    293\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;66;03m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct, EM, total = Evaluation(pretrained_model, tokenizer, validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.eval of BertForQuestionAnswering(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
