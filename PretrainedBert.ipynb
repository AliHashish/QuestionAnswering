{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/DELL/.cache/huggingface/datasets/parquet/plain_text-57edf78d6033ac9a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc953f5665dc40f5bafa5136c8700289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForQuestionAnswering, pipeline, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"squad\")\n",
    "train = dataset['train']\n",
    "validation = dataset['validation']\n",
    "\n",
    "model_checkpoint = \"atharvamundada99/bert-large-question-answering-finetuned-legal\"\n",
    "pretrained_model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model.training)\n",
    "pretrained_model.eval()\n",
    "print(pretrained_model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model=pretrained_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 114/10570 [00:34<26:31,  6.57it/s] c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "  4%|▍         | 439/10570 [04:16<2:09:14,  1.31it/s]c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "  9%|▉         | 999/10570 [10:52<1:54:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 942, out of 1000: 94.2%\n",
      "EM:\t\t\t 762, out of 1000: 76.2%\n",
      "BLEU:\t\t\t 878, out of 1000: 87.8%\n",
      "BLEU Score:\t\t 872.7723680467068, out of 1000: 87.27723680467068%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1999/10570 [21:14<1:42:44,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 1869, out of 2000: 93.45%\n",
      "EM:\t\t\t 1432, out of 2000: 71.6%\n",
      "BLEU:\t\t\t 1703, out of 2000: 85.15%\n",
      "BLEU Score:\t\t 1697.4421047529827, out of 2000: 84.87210523764912%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2999/10570 [32:45<1:26:53,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 2799, out of 3000: 93.3%\n",
      "EM:\t\t\t 2083, out of 3000: 69.43333333333334%\n",
      "BLEU:\t\t\t 2507, out of 3000: 83.56666666666666%\n",
      "BLEU Score:\t\t 2508.141037469119, out of 3000: 83.60470124897064%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3999/10570 [43:59<47:38,  2.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 3728, out of 4000: 93.2%\n",
      "EM:\t\t\t 2750, out of 4000: 68.75%\n",
      "BLEU:\t\t\t 3308, out of 4000: 82.7%\n",
      "BLEU Score:\t\t 3317.115421181209, out of 4000: 82.92788552953022%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4999/10570 [1:01:52<1:55:52,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 4651, out of 5000: 93.02%\n",
      "EM:\t\t\t 3317, out of 5000: 66.34%\n",
      "BLEU:\t\t\t 4056, out of 5000: 81.12%\n",
      "BLEU Score:\t\t 4067.8638478020785, out of 5000: 81.35727695604156%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5999/10570 [1:16:08<1:13:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 5601, out of 6000: 93.35%\n",
      "EM:\t\t\t 4042, out of 6000: 67.36666666666666%\n",
      "BLEU:\t\t\t 4891, out of 6000: 81.51666666666667%\n",
      "BLEU Score:\t\t 4909.089732703673, out of 6000: 81.81816221172788%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6999/10570 [1:30:13<40:30,  1.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 6494, out of 7000: 92.77142857142857%\n",
      "EM:\t\t\t 4693, out of 7000: 67.04285714285714%\n",
      "BLEU:\t\t\t 5667, out of 7000: 80.95714285714286%\n",
      "BLEU Score:\t\t 5691.8794216420865, out of 7000: 81.31256316631551%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7999/10570 [1:43:23<40:44,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 7429, out of 8000: 92.8625%\n",
      "EM:\t\t\t 5390, out of 8000: 67.375%\n",
      "BLEU:\t\t\t 6491, out of 8000: 81.1375%\n",
      "BLEU Score:\t\t 6516.97302106118, out of 8000: 81.46216276326474%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8999/10570 [1:57:23<19:11,  1.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 8362, out of 9000: 92.91111111111111%\n",
      "EM:\t\t\t 5986, out of 9000: 66.5111111111111%\n",
      "BLEU:\t\t\t 7270, out of 9000: 80.77777777777777%\n",
      "BLEU Score:\t\t 7292.617317963844, out of 9000: 81.02908131070937%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9999/10570 [2:09:58<06:42,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\t\t 9279, out of 10000: 92.79%\n",
      "EM:\t\t\t 6578, out of 10000: 65.78%\n",
      "BLEU:\t\t\t 8042, out of 10000: 80.42%\n",
      "BLEU Score:\t\t 8068.880321520323, out of 10000: 80.68880321520324%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [2:17:41<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9789, out of 10570: 92.61116367076632%\n",
      "EM: 6901, out of 10570: 65.28855250709556%\n",
      "BLEU: 8477, out of 10570: 80.19867549668874%\n",
      "BLEU Score: 8501.452133048304, out of 10570: 80.43001071947307%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "EM = 0\n",
    "BLEU = 0\n",
    "bblleeuu = 0\n",
    "errors = []\n",
    "for record in tqdm(validation):\n",
    "        # try:\n",
    "                total += 1\n",
    "                if (total % 1000 == 0):\n",
    "                        print(f\"Correct:\\t\\t {correct}, out of {total}: {100*correct/total}%\")\n",
    "                        print(f\"EM:\\t\\t\\t {EM}, out of {total}: {100*EM/total}%\")\n",
    "                        print(f\"BLEU:\\t\\t\\t {BLEU}, out of {total}: {100*BLEU/total}%\")\n",
    "                        print(f\"BLEU Score:\\t\\t {bblleeuu}, out of {total}: {100*bblleeuu/total}%\")\n",
    "                result = question_answerer(question=record['question'], context=record['context'], truncation=True, padding=True, return_tensors='pt')\n",
    "                # result = QA(model, tokenizer,record['question'], record['context'])\n",
    "                n = min(len(result['answer'].split()), 4)\n",
    "                # n = min(len(result.split()), 4)\n",
    "                if n == 0:\n",
    "                        BLEUscore = 0\n",
    "                else:\n",
    "                        weights = [1.0/n]*n\n",
    "                        BLEUscore = nltk.translate.bleu_score.sentence_bleu([record['answers']['text'][0].lower()], result['answer'].lower(), weights=weights)\n",
    "                        # BLEUscore = nltk.translate.bleu_score.sentence_bleu([record['answers']['text'][0].lower()], result.lower(), weights=weights)\n",
    "                if result['answer'] != '' and (result['answer'].lower() in record['answers']['text'][0].lower() or record['answers']['text'][0].lower() in result['answer'].lower()):\n",
    "                # if result != '' and (result.lower() in record['answers']['text'][0].lower() or record['answers']['text'][0].lower() in result.lower()):\n",
    "                        correct += 1\n",
    "                if record['answers']['text'][0].lower() == result['answer'].lower():\n",
    "                # if record['answers']['text'][0].lower() == result.lower():\n",
    "                        EM += 1\n",
    "                if BLEUscore > 0.5:\n",
    "                        BLEU += 1\n",
    "                bblleeuu += BLEUscore\n",
    "                 \n",
    "        # except Exception as e:\n",
    "        #         errors.append(total)\n",
    "        #         print(f\"Error at {total}: {e}\")\n",
    "        #         continue\n",
    "print(f\"Correct: {correct}, out of {total}: {100*correct/total}%\")\n",
    "print(f\"EM: {EM}, out of {total}: {100*EM/total}%\")\n",
    "print(f\"BLEU: {BLEU}, out of {total}: {100*BLEU/total}%\")\n",
    "print(f\"BLEU Score: {bblleeuu}, out of {total}: {100*bblleeuu/total}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
